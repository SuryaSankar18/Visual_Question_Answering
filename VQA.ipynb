{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import requests\n",
    "from PIL import Image\n",
    "from transformers import  ViltProcessor, ViltForQuestionAnswering\n",
    "from IPython.display import display, Javascript, HTML\n",
    "from google.colab.output import eval_js\n",
    "from google.colab import files\n",
    "import cv2\n",
    "import numpy as np\n",
    "import base64\n",
    "import matplotlib.pyplot as plt  # For displaying images in Colab\n",
    "\n",
    "# Function to capture image from the webcam\n",
    "def capture_image_from_webcam():\n",
    "    display(Javascript('''\n",
    "        async function captureImage() {\n",
    "            const div = document.createElement('div');\n",
    "            document.body.appendChild(div);\n",
    "            const video = document.createElement('video');\n",
    "            video.style.display = 'block';\n",
    "            div.appendChild(video);\n",
    "\n",
    "            // Request access to the webcam\n",
    "            const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
    "            video.srcObject = stream;\n",
    "            await video.play();\n",
    "\n",
    "            // Create a button to capture the frame\n",
    "            const button = document.createElement('button');\n",
    "            button.innerText = 'Capture Image';\n",
    "            div.appendChild(button);\n",
    "\n",
    "            await new Promise((resolve) => button.onclick = resolve);\n",
    "\n",
    "            // Capture the frame from the webcam\n",
    "            const canvas = document.createElement('canvas');\n",
    "            canvas.width = video.videoWidth;\n",
    "            canvas.height = video.videoHeight;\n",
    "            const ctx = canvas.getContext('2d');\n",
    "            ctx.drawImage(video, 0, 0);\n",
    "\n",
    "            // Stop the video stream\n",
    "            stream.getTracks().forEach(track => track.stop());\n",
    "\n",
    "            const imageDataUrl = canvas.toDataURL('image/png');\n",
    "            div.remove();\n",
    "            return imageDataUrl;\n",
    "        }\n",
    "    '''))\n",
    "    # Call the JavaScript function that has been injected into the notebook\n",
    "    data_url = eval_js('captureImage()')\n",
    "    return data_url\n",
    "\n",
    "# Function to upload an image from the device\n",
    "def upload_image_from_device():\n",
    "    uploaded = files.upload()\n",
    "    for filename in uploaded.keys():\n",
    "        return Image.open(filename)\n",
    "\n",
    "# Function to convert Data URL to image\n",
    "def convert_data_url_to_image(data_url):\n",
    "    # Decode base64 image from Data URL to an image\n",
    "    encoded_data = data_url.split(',')[1]\n",
    "    nparr = np.frombuffer(base64.b64decode(encoded_data), np.uint8)\n",
    "    image = cv2.imdecode(nparr, cv2.IMREAD_COLOR)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert BGR (OpenCV format) to RGB (PIL format)\n",
    "    return Image.fromarray(image)\n",
    "\n",
    "# Function to let the user choose between uploading or capturing an image\n",
    "def get_image_from_user():\n",
    "    print(\"Choose an option:\")\n",
    "    print(\"1. Upload an image from your device\")\n",
    "    print(\"2. Capture a photo from your camera\")\n",
    "    choice = input(\"Enter your choice (1 or 2): \")\n",
    "\n",
    "    if choice == \"1\":\n",
    "        print(\"Please upload an image from your device.\")\n",
    "        image = upload_image_from_device()\n",
    "    elif choice == \"2\":\n",
    "        print(\"Please capture an image from the webcam.\")\n",
    "        data_url = capture_image_from_webcam()\n",
    "        image = convert_data_url_to_image(data_url)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid choice. Please choose 1 or 2.\")\n",
    "\n",
    "    return image\n",
    "\n",
    "# Step 1: Get the image from the user\n",
    "raw_image = get_image_from_user()\n",
    "\n",
    "# Display the captured/uploaded image\n",
    "print(\"Image:\")\n",
    "plt.imshow(raw_image)\n",
    "plt.axis('off')  # Hide axis for cleaner display\n",
    "plt.show()\n",
    "\n",
    "# Step 2: Load the BLIP model and processor\n",
    "print(\"Loading BLIP model... Please wait.\")\n",
    "processor = ViltProcessor.from_pretrained(\"dandelin/vilt-b32-finetuned-vqa\")\n",
    "model = ViltForQuestionAnswering.from_pretrained(\"dandelin/vilt-b32-finetuned-vqa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Step 3: Ask a question about the image\n",
    "question = \"\"\n",
    "print(f\"Question: {question}\")\n",
    "inputs = processor(raw_image, question, return_tensors=\"pt\")\n",
    "\n",
    "# Step 4: Generate an answer using the BLIP model\n",
    "print(\"Processing image and generating an answer...\")\n",
    "out = model.generate(**inputs)\n",
    "answer = processor.decode(out[0], skip_special_tokens=True)\n",
    "\n",
    "# Display the answer\n",
    "print(\"Answer:\", answer)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
